{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ysuter/FHNW-BAI-ComputerVision/blob/main/W02/bildhistogramme_tutorial.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fMdwnIBtwJgB"
      },
      "source": [
        "# üìä Bildhistogramme - Von den Grundlagen bis zur Anwendung\n",
        "\n",
        "**Lernziele:**\n",
        "- ‚úÖ Verstehen, was Bildhistogramme sind und warum sie wichtig sind\n",
        "- ‚úÖ RGB vs. Graustufen-Histogramme interpretieren k√∂nnen\n",
        "- ‚úÖ Histogram Equalization anwenden und verstehen\n",
        "- ‚úÖ CLAHE (Contrast Limited Adaptive Histogram Equalization) kennenlernen\n",
        "- ‚úÖ Histogram Matching und Contrast Stretching nutzen\n",
        "- ‚úÖ Praktische Anwendungen in der Bildverbesserung\n",
        "\n",
        "---\n",
        "\n",
        "## ü§î Motivation: Warum Histogramme?\n",
        "\n",
        "**Ein Histogramm zeigt auf einen Blick:**\n",
        "- üì∏ Ist das Bild √ºber- oder unterbelichtet?\n",
        "- üé® Nutzt das Bild den vollen Dynamikbereich?\n",
        "- üåì Ist der Kontrast hoch oder niedrig?\n",
        "- üîç Wo liegen die Hauptinformationen im Bild?\n",
        "\n",
        "**Anwendungen:**\n",
        "- Automatische Bildverbesserung (Smartphones!)\n",
        "- Kontrastanpassung\n",
        "- Details hervorheben\n",
        "- Qualit√§tskontrolle (gleichm√§ssige Belichtung pr√ºfen)\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cgph4K5mwJgD"
      },
      "source": [
        "## üì¶ Setup & Installation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HNVUeFv3wJgD"
      },
      "outputs": [],
      "source": [
        "# Bibliotheken installieren\n",
        "!pip install opencv-python-headless scikit-image ipywidgets -q\n",
        "\n",
        "# Imports\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "import requests\n",
        "from io import BytesIO\n",
        "from google.colab import files\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display, clear_output, HTML\n",
        "\n",
        "# Plotting-Einstellungen\n",
        "plt.rcParams['figure.figsize'] = (14, 8)\n",
        "plt.rcParams['font.size'] = 10\n",
        "\n",
        "print(\"‚úÖ Alle Bibliotheken geladen!\")\n",
        "print(f\"OpenCV Version: {cv2.__version__}\")\n",
        "print(f\"NumPy Version: {np.__version__}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "moCwr_LIwJgE"
      },
      "source": [
        "## üé® Hilfsfunktionen"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZTXPqhuTwJgE"
      },
      "outputs": [],
      "source": [
        "def load_image_from_url(url):\n",
        "    \"\"\"L√§dt Bild von URL mit verbessertem Error Handling\"\"\"\n",
        "    try:\n",
        "        response = requests.get(url, timeout=10)\n",
        "        response.raise_for_status()\n",
        "\n",
        "        # Versuche Bild zu √∂ffnen\n",
        "        img = Image.open(BytesIO(response.content))\n",
        "\n",
        "        # Konvertiere zu RGB falls n√∂tig\n",
        "        if img.mode not in ('RGB', 'L'):\n",
        "            img = img.convert('RGB')\n",
        "\n",
        "        img_array = np.array(img)\n",
        "\n",
        "        if len(img_array.shape) == 2:  # Grayscale\n",
        "            return cv2.cvtColor(img_array, cv2.COLOR_GRAY2BGR)\n",
        "        elif len(img_array.shape) == 3:\n",
        "            if img_array.shape[2] == 4:  # RGBA\n",
        "                return cv2.cvtColor(img_array, cv2.COLOR_RGBA2BGR)\n",
        "            elif img_array.shape[2] == 3:  # RGB\n",
        "                return cv2.cvtColor(img_array, cv2.COLOR_RGB2BGR)\n",
        "        return None\n",
        "    except Exception as e:\n",
        "        print(f\"‚ö†Ô∏è Fehler: {str(e)[:60]}...\")\n",
        "        return None\n",
        "\n",
        "def show_image_with_histogram(image, title=\"Bild\", channels='bgr'):\n",
        "    \"\"\"\n",
        "    Zeigt Bild und zugeh√∂riges Histogramm\n",
        "    channels: 'bgr' f√ºr Farbbild, 'gray' f√ºr Graustufenbild\n",
        "    \"\"\"\n",
        "    fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "    # Bild anzeigen\n",
        "    if len(image.shape) == 3:\n",
        "        axes[0].imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
        "    else:\n",
        "        axes[0].imshow(image, cmap='gray')\n",
        "    axes[0].set_title(title, fontsize=12, fontweight='bold')\n",
        "    axes[0].axis('off')\n",
        "\n",
        "    # Histogramm berechnen und anzeigen\n",
        "    if channels == 'gray':\n",
        "        # Graustufenhistogramm\n",
        "        if len(image.shape) == 3:\n",
        "            gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "        else:\n",
        "            gray = image\n",
        "        hist = cv2.calcHist([gray], [0], None, [256], [0, 256])\n",
        "        axes[1].plot(hist, color='black', linewidth=2)\n",
        "        axes[1].fill_between(range(256), hist.flatten(), alpha=0.3, color='gray')\n",
        "        axes[1].set_xlim([0, 256])\n",
        "        axes[1].set_title('Histogramm (Grayscale)', fontsize=12, fontweight='bold')\n",
        "    else:\n",
        "        # RGB/BGR Histogramm\n",
        "        colors = ('b', 'g', 'r')\n",
        "        color_names = ('Blau', 'Gr√ºn', 'Rot')\n",
        "        for i, (color, name) in enumerate(zip(colors, color_names)):\n",
        "            hist = cv2.calcHist([image], [i], None, [256], [0, 256])\n",
        "            axes[1].plot(hist, color=color, linewidth=2, label=name, alpha=0.7)\n",
        "        axes[1].set_xlim([0, 256])\n",
        "        axes[1].set_title('Histogramm (RGB)', fontsize=12, fontweight='bold')\n",
        "        axes[1].legend()\n",
        "\n",
        "    axes[1].set_xlabel('Intensit√§t (0-255)')\n",
        "    axes[1].set_ylabel('H√§ufigkeit (Pixel-Anzahl)')\n",
        "    axes[1].grid(alpha=0.3)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "print(\"‚úÖ Hilfsfunktionen definiert!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t1XbUTpJwJgE"
      },
      "source": [
        "## üñºÔ∏è Testbilder laden"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C4innl-mwJgE"
      },
      "outputs": [],
      "source": [
        "# Verschiedene Beispielbilder f√ºr unterschiedliche Histogramm-Charakteristiken\n",
        "print(\"üì• Lade Beispielbilder...\\n\")\n",
        "\n",
        "# Bild 1: Standard-Testbild (gut belichtet)\n",
        "url_normal = \"https://sipi.usc.edu/database/preview/misc/4.2.03.png\"\n",
        "img_normal = load_image_from_url(url_normal)\n",
        "\n",
        "# Bild 2: Dunkles Bild erstellen (unterbelichtet)\n",
        "if img_normal is not None:\n",
        "    img_dark = (img_normal * 0.3).astype(np.uint8)\n",
        "\n",
        "# Bild 3: Helles Bild erstellen (√ºberbelichtet)\n",
        "    img_bright = np.clip(img_normal * 1.5 + 50, 0, 255).astype(np.uint8)\n",
        "\n",
        "# Bild 4: Kontrastarmes Bild\n",
        "    img_low_contrast = ((img_normal - 128) * 0.3 + 128).astype(np.uint8)\n",
        "\n",
        "    print(\"‚úÖ Alle Testbilder erstellt!\")\n",
        "    print(\"\\nüìä Wir haben jetzt 4 Bilder mit verschiedenen Eigenschaften:\")\n",
        "    print(\"   1. Normal belichtet\")\n",
        "    print(\"   2. Unterbelichtet (dunkel)\")\n",
        "    print(\"   3. √úberbelichtet (hell)\")\n",
        "    print(\"   4. Niedriger Kontrast\")\n",
        "else:\n",
        "    print(\"‚ùå Fehler beim Laden des Bildes\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4COg3B7cwJgE"
      },
      "source": [
        "---\n",
        "\n",
        "# üìä Teil 1: Histogramm-Grundlagen\n",
        "\n",
        "## Was ist ein Histogramm?\n",
        "\n",
        "**Definition:**\n",
        "Ein Histogramm zeigt die Verteilung der Pixelintensit√§ten in einem Bild.\n",
        "\n",
        "**Achsen:**\n",
        "- **X-Achse**: Intensit√§tswerte (0-255 bei 8-bit Bildern)\n",
        "  - 0 = Schwarz\n",
        "  - 255 = Wei√ü\n",
        "- **Y-Achse**: Anzahl der Pixel mit dieser Intensit√§t\n",
        "\n",
        "**Interpretation:**\n",
        "- **Links (dunkle Werte)**: Schatten\n",
        "- **Mitte**: Mittelt√∂ne\n",
        "- **Rechts (helle Werte)**: Lichter/Highlights\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-DmO-xRFwJgF"
      },
      "source": [
        "## 1.1 Vergleich verschiedener Belichtungen"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mvr70k1nwJgF"
      },
      "outputs": [],
      "source": [
        "if img_normal is not None:\n",
        "    print(\"üìä Vergleich der Histogramme bei unterschiedlichen Belichtungen\\n\")\n",
        "    print(\"=\"*70)\n",
        "\n",
        "    # Normal\n",
        "    print(\"\\n1Ô∏è‚É£ NORMAL BELICHTETES BILD:\")\n",
        "    print(\"   ‚Üí Histogramm gut verteilt √ºber gesamten Bereich\")\n",
        "    show_image_with_histogram(img_normal, \"Normal belichtet\", 'gray')\n",
        "\n",
        "    # Dunkel\n",
        "    print(\"\\n2Ô∏è‚É£ UNTERBELICHTETES BILD (zu dunkel):\")\n",
        "    print(\"   ‚Üí Histogramm nach LINKS verschoben (dunkle Werte)\")\n",
        "    print(\"   ‚Üí Viele Pixel im Schattenbereich (0-100)\")\n",
        "    show_image_with_histogram(img_dark, \"Unterbelichtet\", 'gray')\n",
        "\n",
        "    # Hell\n",
        "    print(\"\\n3Ô∏è‚É£ √úBERBELICHTETES BILD (zu hell):\")\n",
        "    print(\"   ‚Üí Histogramm nach RECHTS verschoben (helle Werte)\")\n",
        "    print(\"   ‚Üí Viele Pixel im Highlight-Bereich (150-255)\")\n",
        "    show_image_with_histogram(img_bright, \"√úberbelichtet\", 'gray')\n",
        "\n",
        "    # Niedriger Kontrast\n",
        "    print(\"\\n4Ô∏è‚É£ NIEDRIGER KONTRAST:\")\n",
        "    print(\"   ‚Üí Histogramm SCHMAL und ZENTRIERT\")\n",
        "    print(\"   ‚Üí Nutzt nicht den vollen Dynamikbereich (0-255)\")\n",
        "    print(\"   ‚Üí Bild wirkt 'flau' oder 'neblig'\")\n",
        "    show_image_with_histogram(img_low_contrast, \"Niedriger Kontrast\", 'gray')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3OpV9eP8wJgF"
      },
      "source": [
        "### üí° Interpretation lernen:\n",
        "\n",
        "**Gutes Histogramm:**\n",
        "- ‚úÖ Gleichm√§√üig verteilt √ºber 0-255\n",
        "- ‚úÖ Keine gro√üen L√ºcken\n",
        "- ‚úÖ Nicht zu stark an den R√§ndern (Clipping vermeiden)\n",
        "\n",
        "**Problematische Histogramme:**\n",
        "- ‚ùå Zu weit links ‚Üí unterbelichtet\n",
        "- ‚ùå Zu weit rechts ‚Üí √ºberbelichtet\n",
        "- ‚ùå Schmal und zentriert ‚Üí niedriger Kontrast\n",
        "- ‚ùå Spitzen an 0 oder 255 ‚Üí Clipping (Informationsverlust!)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RsCC3cRrwJgF"
      },
      "source": [
        "## 1.2 RGB-Farbhistogramme"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m_TQaA9FwJgF"
      },
      "outputs": [],
      "source": [
        "if img_normal is not None:\n",
        "    print(\"üé® RGB-Farbhistogramme\\n\")\n",
        "    print(\"=\"*70)\n",
        "    print(\"\\nFarbbilder haben 3 separate Histogramme:\")\n",
        "    print(\"   üî¥ Rot-Kanal\")\n",
        "    print(\"   üü¢ Gr√ºn-Kanal\")\n",
        "    print(\"   üîµ Blau-Kanal\\n\")\n",
        "\n",
        "    show_image_with_histogram(img_normal, \"Farbbild mit RGB-Histogramm\", 'bgr')\n",
        "\n",
        "    print(\"\\nüí° Farbstiche erkennen:\")\n",
        "    print(\"   - Wenn ein Kanal dominiert ‚Üí Farbstich in dieser Farbe\")\n",
        "    print(\"   - Alle drei Kan√§le √§hnlich ‚Üí neutrales Grau\")\n",
        "    print(\"   - Gro√üe Unterschiede zwischen Kan√§len ‚Üí bunte Szene\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CVPK8mEkwJgF"
      },
      "source": [
        "## 1.3 Histogramm manuell berechnen"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QdYi_gfJwJgF"
      },
      "outputs": [],
      "source": [
        "# Zeigen wir, wie ein Histogramm intern berechnet wird\n",
        "print(\"üîç Histogramm-Berechnung im Detail\\n\")\n",
        "\n",
        "# Kleines Beispielbild erstellen\n",
        "small_img = np.array([\n",
        "    [0, 50, 100],\n",
        "    [50, 100, 150],\n",
        "    [100, 150, 200]\n",
        "], dtype=np.uint8)\n",
        "\n",
        "print(\"Beispiel-Bild (3x3 Pixel):\")\n",
        "print(small_img)\n",
        "print()\n",
        "\n",
        "# Manuelle Berechnung\n",
        "unique, counts = np.unique(small_img, return_counts=True)\n",
        "print(\"Histogramm-Tabelle:\")\n",
        "print(\"-\" * 30)\n",
        "print(f\"{'Intensit√§t':<15} {'Anzahl Pixel':<15}\")\n",
        "print(\"-\" * 30)\n",
        "for intensity, count in zip(unique, counts):\n",
        "    print(f\"{intensity:<15} {count:<15}\")\n",
        "print(\"-\" * 30)\n",
        "\n",
        "# Visualisierung\n",
        "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
        "\n",
        "axes[0].imshow(small_img, cmap='gray', interpolation='nearest')\n",
        "axes[0].set_title('Beispiel-Bild (3x3)', fontweight='bold')\n",
        "axes[0].axis('off')\n",
        "\n",
        "# F√ºr alle 256 Werte\n",
        "hist_full = np.zeros(256)\n",
        "for intensity, count in zip(unique, counts):\n",
        "    hist_full[intensity] = count\n",
        "\n",
        "axes[1].bar(range(256), hist_full, width=1, color='gray', edgecolor='black')\n",
        "axes[1].set_xlim([0, 255])\n",
        "axes[1].set_title('Histogramm', fontweight='bold')\n",
        "axes[1].set_xlabel('Intensit√§t')\n",
        "axes[1].set_ylabel('Anzahl Pixel')\n",
        "axes[1].grid(alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"\\nüí° So funktioniert's:\")\n",
        "print(\"   1. F√ºr jede Intensit√§t 0-255 z√§hlen wir die Pixel\")\n",
        "print(\"   2. Das Ergebnis ist das Histogramm\")\n",
        "print(\"   3. Summe aller Balken = Gesamtzahl Pixel im Bild\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zV1mZRowwJgF"
      },
      "source": [
        "---\n",
        "\n",
        "# üîß Teil 2: Histogram Equalization (Standard)\n",
        "\n",
        "## Was ist Histogram Equalization?\n",
        "\n",
        "**Ziel:** Verbesserung des Kontrasts durch Umverteilung der Intensit√§tswerte\n",
        "\n",
        "**Idee:**\n",
        "- Spreize das Histogramm √ºber den gesamten Bereich (0-255)\n",
        "- H√§ufige Intensit√§ten werden weiter gespreizt\n",
        "- Seltene Intensit√§ten werden komprimiert\n",
        "\n",
        "**Mathematik (vereinfacht):**\n",
        "1. Berechne **kumulative Verteilungsfunktion** (CDF)\n",
        "2. Normalisiere CDF auf 0-255\n",
        "3. Mappe alte Intensit√§ten auf neue\n",
        "\n",
        "**Resultat:**\n",
        "- Idealerweise: gleichm√§√üig verteiltes Histogramm\n",
        "- Maximaler Kontrast\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CInN0hKywJgF"
      },
      "source": [
        "## 2.1 Histogram Equalization anwenden"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JA4Ha6mTwJgG"
      },
      "outputs": [],
      "source": [
        "def apply_histogram_equalization(image):\n",
        "    \"\"\"\n",
        "    Wendet Histogram Equalization auf Graustufenbild an\n",
        "    \"\"\"\n",
        "    if len(image.shape) == 3:\n",
        "        # Konvertiere zu Graustufen falls Farbbild\n",
        "        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "    else:\n",
        "        gray = image.copy()\n",
        "\n",
        "    # Histogram Equalization\n",
        "    equalized = cv2.equalizeHist(gray)\n",
        "\n",
        "    return gray, equalized\n",
        "\n",
        "def show_equalization_comparison(original, title=\"\"):\n",
        "    \"\"\"\n",
        "    Zeigt Vorher-Nachher-Vergleich von Histogram Equalization\n",
        "    \"\"\"\n",
        "    gray, equalized = apply_histogram_equalization(original)\n",
        "\n",
        "    fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
        "\n",
        "    # Original Bild\n",
        "    axes[0, 0].imshow(gray, cmap='gray')\n",
        "    axes[0, 0].set_title('Original', fontsize=12, fontweight='bold')\n",
        "    axes[0, 0].axis('off')\n",
        "\n",
        "    # Original Histogramm\n",
        "    hist_orig = cv2.calcHist([gray], [0], None, [256], [0, 256])\n",
        "    axes[0, 1].plot(hist_orig, color='black', linewidth=2)\n",
        "    axes[0, 1].fill_between(range(256), hist_orig.flatten(), alpha=0.3, color='gray')\n",
        "    axes[0, 1].set_xlim([0, 256])\n",
        "    axes[0, 1].set_title('Original Histogramm', fontsize=12, fontweight='bold')\n",
        "    axes[0, 1].set_xlabel('Intensit√§t')\n",
        "    axes[0, 1].set_ylabel('H√§ufigkeit')\n",
        "    axes[0, 1].grid(alpha=0.3)\n",
        "\n",
        "    # Equalized Bild\n",
        "    axes[1, 0].imshow(equalized, cmap='gray')\n",
        "    axes[1, 0].set_title('Nach Histogram Equalization', fontsize=12, fontweight='bold')\n",
        "    axes[1, 0].axis('off')\n",
        "\n",
        "    # Equalized Histogramm\n",
        "    hist_eq = cv2.calcHist([equalized], [0], None, [256], [0, 256])\n",
        "    axes[1, 1].plot(hist_eq, color='blue', linewidth=2)\n",
        "    axes[1, 1].fill_between(range(256), hist_eq.flatten(), alpha=0.3, color='blue')\n",
        "    axes[1, 1].set_xlim([0, 256])\n",
        "    axes[1, 1].set_title('Equalized Histogramm', fontsize=12, fontweight='bold')\n",
        "    axes[1, 1].set_xlabel('Intensit√§t')\n",
        "    axes[1, 1].set_ylabel('H√§ufigkeit')\n",
        "    axes[1, 1].grid(alpha=0.3)\n",
        "\n",
        "    if title:\n",
        "        fig.suptitle(title, fontsize=14, fontweight='bold', y=1.00)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    # Statistiken\n",
        "    print(f\"üìä Statistiken:\")\n",
        "    print(f\"   Original  ‚Üí Min: {gray.min()}, Max: {gray.max()}, Mean: {gray.mean():.1f}, Std: {gray.std():.1f}\")\n",
        "    print(f\"   Equalized ‚Üí Min: {equalized.min()}, Max: {equalized.max()}, Mean: {equalized.mean():.1f}, Std: {equalized.std():.1f}\")\n",
        "    print(f\"\\n   ‚û°Ô∏è Dynamikbereich wurde von [{gray.min()}-{gray.max()}] auf [{equalized.min()}-{equalized.max()}] erweitert!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uKW-eGGxwJgG"
      },
      "outputs": [],
      "source": [
        "if img_dark is not None:\n",
        "    print(\"üåì BEISPIEL 1: Unterbelichtetes Bild verbessern\\n\")\n",
        "    print(\"=\"*70)\n",
        "    show_equalization_comparison(img_dark, \"Histogram Equalization - Unterbelichtetes Bild\")\n",
        "    print(\"\\nüí° Beobachtung:\")\n",
        "    print(\"   ‚úÖ Dunkles Bild wurde aufgehellt\")\n",
        "    print(\"   ‚úÖ Details in Schatten sind jetzt sichtbar\")\n",
        "    print(\"   ‚úÖ Histogramm ist breiter verteilt\")\n",
        "    print(\"   ‚ö†Ô∏è  Aber: Kann auch Rauschen verst√§rken!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GF99EhuJwJgG"
      },
      "outputs": [],
      "source": [
        "if img_low_contrast is not None:\n",
        "    print(\"\\n\\nüìâ BEISPIEL 2: Kontrastarmes Bild verbessern\\n\")\n",
        "    print(\"=\"*70)\n",
        "    show_equalization_comparison(img_low_contrast, \"Histogram Equalization - Niedriger Kontrast\")\n",
        "    print(\"\\nüí° Beobachtung:\")\n",
        "    print(\"   ‚úÖ Kontrast deutlich erh√∂ht\")\n",
        "    print(\"   ‚úÖ Bild wirkt nicht mehr 'flau'\")\n",
        "    print(\"   ‚úÖ Histogramm nutzt vollen Bereich 0-255\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N5n6HI4rwJgG"
      },
      "source": [
        "## 2.2 Histogram Equalization f√ºr Farbbilder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-Un25tTTwJgG"
      },
      "outputs": [],
      "source": [
        "def equalize_color_image(image):\n",
        "    \"\"\"\n",
        "    Histogram Equalization f√ºr Farbbilder\n",
        "    Arbeitet im YCrCb-Farbraum (nur Luminanz wird equalized)\n",
        "    \"\"\"\n",
        "    # Konvertiere BGR zu YCrCb\n",
        "    ycrcb = cv2.cvtColor(image, cv2.COLOR_BGR2YCrCb)\n",
        "\n",
        "    # Equalize nur den Y-Kanal (Luminanz/Helligkeit)\n",
        "    ycrcb[:, :, 0] = cv2.equalizeHist(ycrcb[:, :, 0])\n",
        "\n",
        "    # Zur√ºck zu BGR\n",
        "    result = cv2.cvtColor(ycrcb, cv2.COLOR_YCrCb2BGR)\n",
        "\n",
        "    return result\n",
        "\n",
        "if img_dark is not None:\n",
        "    print(\"üé® Histogram Equalization f√ºr FARBBILDER\\n\")\n",
        "    print(\"=\"*70)\n",
        "    print(\"\\nMethode: Equalization im YCrCb-Farbraum\")\n",
        "    print(\"   ‚Üí Nur Luminanz (Y-Kanal) wird equalized\")\n",
        "    print(\"   ‚Üí Farben (Cr, Cb) bleiben erhalten\\n\")\n",
        "\n",
        "    # Dunkles Farbbild equalisieren\n",
        "    equalized_color = equalize_color_image(img_dark)\n",
        "\n",
        "    fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
        "\n",
        "    axes[0].imshow(cv2.cvtColor(img_dark, cv2.COLOR_BGR2RGB))\n",
        "    axes[0].set_title('Original (dunkel)', fontsize=12, fontweight='bold')\n",
        "    axes[0].axis('off')\n",
        "\n",
        "    axes[1].imshow(cv2.cvtColor(equalized_color, cv2.COLOR_BGR2RGB))\n",
        "    axes[1].set_title('Nach Histogram Equalization', fontsize=12, fontweight='bold')\n",
        "    axes[1].axis('off')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    print(\"\\nüí° Warum YCrCb statt RGB?\")\n",
        "    print(\"   - Trennung von Helligkeit (Y) und Farbe (Cr, Cb)\")\n",
        "    print(\"   - Wenn wir RGB-Kan√§le einzeln equalisieren ‚Üí Farbverschiebungen!\")\n",
        "    print(\"   - YCrCb: Nur Helligkeit √§ndern, Farben bleiben nat√ºrlich\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rPXsuSlvwJgG"
      },
      "source": [
        "## 2.3 Probleme von Standard Histogram Equalization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "quN2ildOwJgG"
      },
      "outputs": [],
      "source": [
        "# Demonstriere √úberverst√§rkung bei normalem Bild\n",
        "if img_normal is not None:\n",
        "    print(\"‚ö†Ô∏è PROBLEM: √úberverst√§rkung bei bereits gutem Bild\\n\")\n",
        "    print(\"=\"*70)\n",
        "\n",
        "    show_equalization_comparison(img_normal, \"Problem: Equalization auf gut belichtetem Bild\")\n",
        "\n",
        "    print(\"\\n‚ùå Probleme der Standard-Equalization:\")\n",
        "    print(\"   1. Rauschen wird verst√§rkt\")\n",
        "    print(\"   2. Lokale Details k√∂nnen verloren gehen\")\n",
        "    print(\"   3. √úbertriebener Kontrast (unnat√ºrlich)\")\n",
        "    print(\"   4. Artefakte in gleichm√§√üigen Bereichen\")\n",
        "    print(\"\\n‚úÖ Ansatz: CLAHE (Contrast Limited Adaptive Histogram Equalization)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WVtkERqtwJgG"
      },
      "source": [
        "---\n",
        "\n",
        "# üéØ Teil 3: CLAHE (Contrast Limited Adaptive Histogram Equalization)\n",
        "\n",
        "## Was ist CLAHE?\n",
        "\n",
        "**Verbesserungen gegen√ºber Standard-Equalization:**\n",
        "\n",
        "1. **Adaptive** (lokal statt global)\n",
        "   - Bild wird in kleine Kacheln unterteilt (z.B. 8√ó8)\n",
        "   - Equalization wird f√ºr jede Kachel separat durchgef√ºhrt\n",
        "   - Grenzen werden interpoliert (sanfte √úberg√§nge)\n",
        "\n",
        "2. **Contrast Limited** (begrenzte Verst√§rkung)\n",
        "   - Clip Limit: Maximale Verst√§rkung wird begrenzt\n",
        "   - Verhindert Rauschverst√§rkung\n",
        "   - Nat√ºrlichere Ergebnisse\n",
        "\n",
        "**Parameter:**\n",
        "- **clipLimit**: Schwellwert f√ºr Kontrastverst√§rkung (typisch: 2.0-4.0)\n",
        "- **tileGridSize**: Gr√∂√üe der Kacheln (typisch: 8√ó8)\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YW6IcfuYwJgG"
      },
      "source": [
        "## 3.1 CLAHE anwenden"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gZ-Uh602wJgH"
      },
      "outputs": [],
      "source": [
        "def apply_clahe(image, clip_limit=2.0, tile_grid_size=(8, 8)):\n",
        "    \"\"\"\n",
        "    Wendet CLAHE auf Graustufenbild an\n",
        "    \"\"\"\n",
        "    if len(image.shape) == 3:\n",
        "        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "    else:\n",
        "        gray = image.copy()\n",
        "\n",
        "    # CLAHE-Objekt erstellen\n",
        "    clahe = cv2.createCLAHE(clipLimit=clip_limit, tileGridSize=tile_grid_size)\n",
        "\n",
        "    # Anwenden\n",
        "    clahe_img = clahe.apply(gray)\n",
        "\n",
        "    return gray, clahe_img\n",
        "\n",
        "def compare_equalization_methods(image, title=\"\"):\n",
        "    \"\"\"\n",
        "    Vergleicht Standard-Equalization mit CLAHE\n",
        "    \"\"\"\n",
        "    # Graustufen\n",
        "    if len(image.shape) == 3:\n",
        "        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "    else:\n",
        "        gray = image.copy()\n",
        "\n",
        "    # Standard Equalization\n",
        "    eq_standard = cv2.equalizeHist(gray)\n",
        "\n",
        "    # CLAHE\n",
        "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
        "    eq_clahe = clahe.apply(gray)\n",
        "\n",
        "    # Visualisierung\n",
        "    fig, axes = plt.subplots(2, 3, figsize=(16, 10))\n",
        "\n",
        "    # Zeile 1: Bilder\n",
        "    axes[0, 0].imshow(gray, cmap='gray')\n",
        "    axes[0, 0].set_title('Original', fontsize=12, fontweight='bold')\n",
        "    axes[0, 0].axis('off')\n",
        "\n",
        "    axes[0, 1].imshow(eq_standard, cmap='gray')\n",
        "    axes[0, 1].set_title('Standard Equalization', fontsize=12, fontweight='bold')\n",
        "    axes[0, 1].axis('off')\n",
        "\n",
        "    axes[0, 2].imshow(eq_clahe, cmap='gray')\n",
        "    axes[0, 2].set_title('CLAHE', fontsize=12, fontweight='bold')\n",
        "    axes[0, 2].axis('off')\n",
        "\n",
        "    # Zeile 2: Histogramme\n",
        "    for idx, (img, label) in enumerate([(gray, 'Original'),\n",
        "                                         (eq_standard, 'Standard'),\n",
        "                                         (eq_clahe, 'CLAHE')]):\n",
        "        hist = cv2.calcHist([img], [0], None, [256], [0, 256])\n",
        "        color = 'black' if idx == 0 else 'blue' if idx == 1 else 'green'\n",
        "        axes[1, idx].plot(hist, color=color, linewidth=2)\n",
        "        axes[1, idx].fill_between(range(256), hist.flatten(), alpha=0.3, color=color)\n",
        "        axes[1, idx].set_xlim([0, 256])\n",
        "        axes[1, idx].set_title(f'Histogramm: {label}', fontsize=11, fontweight='bold')\n",
        "        axes[1, idx].set_xlabel('Intensit√§t')\n",
        "        axes[1, idx].set_ylabel('H√§ufigkeit')\n",
        "        axes[1, idx].grid(alpha=0.3)\n",
        "\n",
        "    if title:\n",
        "        fig.suptitle(title, fontsize=14, fontweight='bold', y=0.98)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "if img_dark is not None:\n",
        "    print(\"üîç Vergleich: Standard Equalization vs. CLAHE\\n\")\n",
        "    print(\"=\"*70)\n",
        "    compare_equalization_methods(img_dark, \"Vergleich der Methoden\")\n",
        "\n",
        "    print(\"\\nüìä Beobachtungen:\")\n",
        "    print(\"\\n   Standard Equalization:\")\n",
        "    print(\"   ‚úÖ Maximale Kontrasterh√∂hung\")\n",
        "    print(\"   ‚ùå Kann √ºbertrieben wirken\")\n",
        "    print(\"   ‚ùå Verst√§rkt Rauschen stark\")\n",
        "\n",
        "    print(\"\\n   CLAHE:\")\n",
        "    print(\"   ‚úÖ Nat√ºrlichere Ergebnisse\")\n",
        "    print(\"   ‚úÖ Weniger Rauschverst√§rkung\")\n",
        "    print(\"   ‚úÖ Bessere lokale Details\")\n",
        "    print(\"   ‚ö†Ô∏è  Etwas weniger Kontrast als Standard\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tF-ia04IwJgH"
      },
      "source": [
        "## 3.2 Interaktive CLAHE-Parameter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HUii9OcewJgH"
      },
      "outputs": [],
      "source": [
        "# Interaktive Widgets f√ºr CLAHE-Parameter\n",
        "if img_dark is not None:\n",
        "    print(\"üéõÔ∏è Experimentieren Sie mit CLAHE-Parametern!\\n\")\n",
        "\n",
        "    clip_slider = widgets.FloatSlider(\n",
        "        value=2.0,\n",
        "        min=1.0,\n",
        "        max=10.0,\n",
        "        step=0.5,\n",
        "        description='Clip Limit:',\n",
        "        style={'description_width': 'initial'},\n",
        "        layout=widgets.Layout(width='500px')\n",
        "    )\n",
        "\n",
        "    tile_slider = widgets.IntSlider(\n",
        "        value=8,\n",
        "        min=2,\n",
        "        max=32,\n",
        "        step=2,\n",
        "        description='Tile Size:',\n",
        "        style={'description_width': 'initial'},\n",
        "        layout=widgets.Layout(width='500px')\n",
        "    )\n",
        "\n",
        "    output_clahe = widgets.Output()\n",
        "\n",
        "    def update_clahe(change):\n",
        "        with output_clahe:\n",
        "            clear_output(wait=True)\n",
        "\n",
        "            gray = cv2.cvtColor(img_dark, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "            # CLAHE anwenden\n",
        "            tile_size = (tile_slider.value, tile_slider.value)\n",
        "            clahe = cv2.createCLAHE(clipLimit=clip_slider.value,\n",
        "                                   tileGridSize=tile_size)\n",
        "            result = clahe.apply(gray)\n",
        "\n",
        "            # Anzeigen\n",
        "            fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
        "\n",
        "            axes[0].imshow(gray, cmap='gray')\n",
        "            axes[0].set_title('Original', fontsize=12)\n",
        "            axes[0].axis('off')\n",
        "\n",
        "            axes[1].imshow(result, cmap='gray')\n",
        "            axes[1].set_title(\n",
        "                f'CLAHE (Clip={clip_slider.value:.1f}, Tile={tile_size[0]}√ó{tile_size[1]})',\n",
        "                fontsize=12\n",
        "            )\n",
        "            axes[1].axis('off')\n",
        "\n",
        "            plt.tight_layout()\n",
        "            plt.show()\n",
        "\n",
        "    clip_slider.observe(update_clahe, names='value')\n",
        "    tile_slider.observe(update_clahe, names='value')\n",
        "\n",
        "    display(clip_slider, tile_slider, output_clahe)\n",
        "    update_clahe(None)\n",
        "\n",
        "    print(\"\\nüí° Parameter-Tipps:\")\n",
        "    print(\"   üìä Clip Limit:\")\n",
        "    print(\"      ‚Ä¢ Niedrig (1-2): Sanfte Verst√§rkung, wenig Rauschen\")\n",
        "    print(\"      ‚Ä¢ Mittel (2-4): Guter Kompromiss (Standard)\")\n",
        "    print(\"      ‚Ä¢ Hoch (>4): Starke Verst√§rkung, mehr Rauschen\")\n",
        "    print(\"\\n   üî≤ Tile Size:\")\n",
        "    print(\"      ‚Ä¢ Klein (2-4): Sehr lokal, gut f√ºr Details\")\n",
        "    print(\"      ‚Ä¢ Mittel (8-16): Standard, gute Balance\")\n",
        "    print(\"      ‚Ä¢ Gro√ü (>16): Mehr wie globale Equalization\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1eHDizHzwJgH"
      },
      "source": [
        "---\n",
        "\n",
        "# üìè Teil 4: Contrast Stretching (Lineare Normalisierung)\n",
        "\n",
        "## Was ist Contrast Stretching?\n",
        "\n",
        "**Einfachste Methode zur Kontrastverbesserung:**\n",
        "\n",
        "**Idee:**\n",
        "- Finde minimale und maximale Intensit√§t im Bild\n",
        "- Strecke diesen Bereich auf 0-255\n",
        "\n",
        "**Formel:**\n",
        "```\n",
        "new_pixel = (pixel - min) √ó (255 / (max - min))\n",
        "```\n",
        "\n",
        "**Unterschied zu Histogram Equalization:**\n",
        "- ‚úÖ Einfacher (nur lineare Skalierung)\n",
        "- ‚úÖ Keine Histogramm-√Ñnderung, nur Streckung\n",
        "- ‚ùå Weniger effektiv bei ungleichm√§√üiger Verteilung\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZDdx9ei0wJgH"
      },
      "outputs": [],
      "source": [
        "def contrast_stretching(image):\n",
        "    \"\"\"\n",
        "    Contrast Stretching (Min-Max Normalisierung)\n",
        "    \"\"\"\n",
        "    if len(image.shape) == 3:\n",
        "        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "    else:\n",
        "        gray = image.copy()\n",
        "\n",
        "    # Finde Min und Max\n",
        "    min_val = gray.min()\n",
        "    max_val = gray.max()\n",
        "\n",
        "    # Strecke auf 0-255\n",
        "    stretched = ((gray - min_val) / (max_val - min_val) * 255).astype(np.uint8)\n",
        "\n",
        "    return gray, stretched, min_val, max_val\n",
        "\n",
        "if img_low_contrast is not None:\n",
        "    print(\"üìè Contrast Stretching\\n\")\n",
        "    print(\"=\"*70)\n",
        "\n",
        "    gray, stretched, min_val, max_val = contrast_stretching(img_low_contrast)\n",
        "\n",
        "    fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
        "\n",
        "    # Original\n",
        "    axes[0, 0].imshow(gray, cmap='gray')\n",
        "    axes[0, 0].set_title('Original (niedriger Kontrast)', fontsize=12, fontweight='bold')\n",
        "    axes[0, 0].axis('off')\n",
        "\n",
        "    # Original Histogramm\n",
        "    hist_orig = cv2.calcHist([gray], [0], None, [256], [0, 256])\n",
        "    axes[0, 1].plot(hist_orig, color='black', linewidth=2)\n",
        "    axes[0, 1].axvline(min_val, color='red', linestyle='--', label=f'Min={min_val}')\n",
        "    axes[0, 1].axvline(max_val, color='blue', linestyle='--', label=f'Max={max_val}')\n",
        "    axes[0, 1].fill_between(range(256), hist_orig.flatten(), alpha=0.3, color='gray')\n",
        "    axes[0, 1].set_xlim([0, 256])\n",
        "    axes[0, 1].set_title('Original Histogramm', fontsize=12, fontweight='bold')\n",
        "    axes[0, 1].legend()\n",
        "    axes[0, 1].grid(alpha=0.3)\n",
        "\n",
        "    # Stretched\n",
        "    axes[1, 0].imshow(stretched, cmap='gray')\n",
        "    axes[1, 0].set_title('Nach Contrast Stretching', fontsize=12, fontweight='bold')\n",
        "    axes[1, 0].axis('off')\n",
        "\n",
        "    # Stretched Histogramm\n",
        "    hist_stretched = cv2.calcHist([stretched], [0], None, [256], [0, 256])\n",
        "    axes[1, 1].plot(hist_stretched, color='green', linewidth=2)\n",
        "    axes[1, 1].fill_between(range(256), hist_stretched.flatten(), alpha=0.3, color='green')\n",
        "    axes[1, 1].set_xlim([0, 256])\n",
        "    axes[1, 1].set_title('Stretched Histogramm', fontsize=12, fontweight='bold')\n",
        "    axes[1, 1].grid(alpha=0.3)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    print(f\"\\nüìä Transformation:\")\n",
        "    print(f\"   Alter Bereich: [{min_val} - {max_val}] ({max_val - min_val} Werte genutzt)\")\n",
        "    print(f\"   Neuer Bereich: [0 - 255] (voller Dynamikbereich)\")\n",
        "    print(f\"   Streckfaktor: {255 / (max_val - min_val):.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-uQRzWDCwJgH"
      },
      "source": [
        "## 4.1 Vergleich aller Methoden"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lA_M2CZHwJgH"
      },
      "outputs": [],
      "source": [
        "def compare_all_methods(image):\n",
        "    \"\"\"\n",
        "    Vergleicht alle Kontrast-Verbesserungsmethoden\n",
        "    \"\"\"\n",
        "    if len(image.shape) == 3:\n",
        "        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "    else:\n",
        "        gray = image.copy()\n",
        "\n",
        "    # Alle Methoden anwenden\n",
        "    eq_standard = cv2.equalizeHist(gray)\n",
        "\n",
        "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
        "    eq_clahe = clahe.apply(gray)\n",
        "\n",
        "    min_val, max_val = gray.min(), gray.max()\n",
        "    stretched = ((gray - min_val) / (max_val - min_val) * 255).astype(np.uint8)\n",
        "\n",
        "    # Visualisierung\n",
        "    fig, axes = plt.subplots(2, 4, figsize=(18, 9))\n",
        "\n",
        "    methods = [\n",
        "        (gray, 'Original', 'black'),\n",
        "        (stretched, 'Contrast Stretching', 'green'),\n",
        "        (eq_standard, 'Standard Equalization', 'blue'),\n",
        "        (eq_clahe, 'CLAHE', 'red')\n",
        "    ]\n",
        "\n",
        "    for idx, (img, title, color) in enumerate(methods):\n",
        "        # Bild\n",
        "        axes[0, idx].imshow(img, cmap='gray')\n",
        "        axes[0, idx].set_title(title, fontsize=11, fontweight='bold')\n",
        "        axes[0, idx].axis('off')\n",
        "\n",
        "        # Histogramm\n",
        "        hist = cv2.calcHist([img], [0], None, [256], [0, 256])\n",
        "        axes[1, idx].plot(hist, color=color, linewidth=2)\n",
        "        axes[1, idx].fill_between(range(256), hist.flatten(), alpha=0.3, color=color)\n",
        "        axes[1, idx].set_xlim([0, 256])\n",
        "        axes[1, idx].set_xlabel('Intensit√§t', fontsize=9)\n",
        "        axes[1, idx].set_ylabel('H√§ufigkeit', fontsize=9)\n",
        "        axes[1, idx].grid(alpha=0.3)\n",
        "        axes[1, idx].tick_params(labelsize=8)\n",
        "\n",
        "    plt.suptitle('Vergleich aller Methoden', fontsize=14, fontweight='bold')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "if img_low_contrast is not None:\n",
        "    print(\"üîç Umfassender Vergleich aller Methoden\\n\")\n",
        "    print(\"=\"*70)\n",
        "    compare_all_methods(img_low_contrast)\n",
        "\n",
        "    print(\"\\nüìä Zusammenfassung:\\n\")\n",
        "    print(\"   1Ô∏è‚É£ Contrast Stretching:\")\n",
        "    print(\"      ‚úÖ Einfachste Methode\")\n",
        "    print(\"      ‚úÖ Schnell\")\n",
        "    print(\"      ‚ùå Nur bei schmalen Histogrammen effektiv\")\n",
        "\n",
        "    print(\"\\n   2Ô∏è‚É£ Standard Histogram Equalization:\")\n",
        "    print(\"      ‚úÖ Maximaler Kontrast\")\n",
        "    print(\"      ‚ùå Kann √ºbertrieben wirken\")\n",
        "    print(\"      ‚ùå Verst√§rkt Rauschen\")\n",
        "\n",
        "    print(\"\\n   3Ô∏è‚É£ CLAHE:\")\n",
        "    print(\"      ‚úÖ Beste Gesamtqualit√§t (meist!)\")\n",
        "    print(\"      ‚úÖ Lokale Anpassung\")\n",
        "    print(\"      ‚úÖ Kontrollierbare Verst√§rkung\")\n",
        "    print(\"      ‚ö†Ô∏è  Rechenintensiver\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HzuTq3CowJgH"
      },
      "source": [
        "---\n",
        "\n",
        "# üé® Teil 5: Histogram Matching (Spezifikation)\n",
        "\n",
        "## Was ist Histogram Matching?\n",
        "\n",
        "**Ziel:** Transformiere Histogramm eines Bildes, sodass es einem Referenz-Histogramm √§hnelt\n",
        "\n",
        "**Anwendungen:**\n",
        "- Farbkorrektur (angleichen an Referenzbild)\n",
        "- Stil-Transfer (Histogramm eines Kunstwerks √ºbernehmen)\n",
        "- Normalisierung in Bildserien\n",
        "\n",
        "**Algorithmus:**\n",
        "1. Berechne CDF von Quell- und Zielbild\n",
        "2. Finde Mapping zwischen beiden CDFs\n",
        "3. Wende Mapping auf Quellbild an\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4f09YwT4wJgH"
      },
      "outputs": [],
      "source": [
        "def histogram_matching(source, reference):\n",
        "    \"\"\"\n",
        "    Histogram Matching: Transformiert Histogramm von 'source' zu 'reference'\n",
        "    \"\"\"\n",
        "    # Zu Graustufen falls n√∂tig\n",
        "    if len(source.shape) == 3:\n",
        "        source = cv2.cvtColor(source, cv2.COLOR_BGR2GRAY)\n",
        "    if len(reference.shape) == 3:\n",
        "        reference = cv2.cvtColor(reference, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Berechne Histogramme\n",
        "    hist_source = cv2.calcHist([source], [0], None, [256], [0, 256]).flatten()\n",
        "    hist_ref = cv2.calcHist([reference], [0], None, [256], [0, 256]).flatten()\n",
        "\n",
        "    # Berechne kumulative Verteilungsfunktionen (CDF)\n",
        "    cdf_source = hist_source.cumsum()\n",
        "    cdf_source = cdf_source / cdf_source[-1]  # Normalisieren auf [0, 1]\n",
        "\n",
        "    cdf_ref = hist_ref.cumsum()\n",
        "    cdf_ref = cdf_ref / cdf_ref[-1]\n",
        "\n",
        "    # Erstelle Lookup-Table f√ºr Mapping\n",
        "    lookup_table = np.zeros(256, dtype=np.uint8)\n",
        "\n",
        "    for i in range(256):\n",
        "        # Finde n√§chsten Wert in Referenz-CDF\n",
        "        diff = np.abs(cdf_ref - cdf_source[i])\n",
        "        lookup_table[i] = np.argmin(diff)\n",
        "\n",
        "    # Wende Mapping an\n",
        "    matched = cv2.LUT(source, lookup_table)\n",
        "\n",
        "    return matched\n",
        "\n",
        "if img_dark is not None and img_bright is not None:\n",
        "    print(\"üé® Histogram Matching Demo\\n\")\n",
        "    print(\"=\"*70)\n",
        "    print(\"\\nWir passen das Histogramm des dunklen Bildes an das helle Bild an.\\n\")\n",
        "\n",
        "    # Matching durchf√ºhren\n",
        "    matched = histogram_matching(img_dark, img_bright)\n",
        "\n",
        "    # Zu Graustufen\n",
        "    dark_gray = cv2.cvtColor(img_dark, cv2.COLOR_BGR2GRAY)\n",
        "    bright_gray = cv2.cvtColor(img_bright, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Visualisierung\n",
        "    fig, axes = plt.subplots(2, 3, figsize=(16, 10))\n",
        "\n",
        "    # Zeile 1: Bilder\n",
        "    axes[0, 0].imshow(dark_gray, cmap='gray')\n",
        "    axes[0, 0].set_title('Quellbild (dunkel)', fontsize=12, fontweight='bold')\n",
        "    axes[0, 0].axis('off')\n",
        "\n",
        "    axes[0, 1].imshow(matched, cmap='gray')\n",
        "    axes[0, 1].set_title('Nach Matching', fontsize=12, fontweight='bold')\n",
        "    axes[0, 1].axis('off')\n",
        "\n",
        "    axes[0, 2].imshow(bright_gray, cmap='gray')\n",
        "    axes[0, 2].set_title('Referenzbild (hell)', fontsize=12, fontweight='bold')\n",
        "    axes[0, 2].axis('off')\n",
        "\n",
        "    # Zeile 2: Histogramme\n",
        "    for idx, (img, label, color) in enumerate([\n",
        "        (dark_gray, 'Quelle', 'black'),\n",
        "        (matched, 'Matched', 'purple'),\n",
        "        (bright_gray, 'Referenz', 'orange')\n",
        "    ]):\n",
        "        hist = cv2.calcHist([img], [0], None, [256], [0, 256])\n",
        "        axes[1, idx].plot(hist, color=color, linewidth=2)\n",
        "        axes[1, idx].fill_between(range(256), hist.flatten(), alpha=0.3, color=color)\n",
        "        axes[1, idx].set_xlim([0, 256])\n",
        "        axes[1, idx].set_title(f'Histogramm: {label}', fontsize=11, fontweight='bold')\n",
        "        axes[1, idx].set_xlabel('Intensit√§t')\n",
        "        axes[1, idx].set_ylabel('H√§ufigkeit')\n",
        "        axes[1, idx].grid(alpha=0.3)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    print(\"\\nüí° Beobachtung:\")\n",
        "    print(\"   ‚Üí Das 'Matched' Histogramm √§hnelt dem 'Referenz' Histogramm\")\n",
        "    print(\"   ‚Üí Das Bild wurde entsprechend transformiert\")\n",
        "    print(\"   ‚Üí N√ºtzlich f√ºr: Farbkorrektur, Stil-Transfer, Bildnormalisierung\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AmpTdQfVwJgI"
      },
      "source": [
        "---\n",
        "\n",
        "# üì∏ Teil 6: Praktische Anwendungen\n",
        "\n",
        "## Eigenes Bild hochladen und bearbeiten"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qb4xy88bwJgI"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "\n",
        "print(\"üì§ Laden Sie Ihr eigenes Bild hoch!\\n\")\n",
        "uploaded = files.upload()\n",
        "\n",
        "if uploaded:\n",
        "    filename = list(uploaded.keys())[0]\n",
        "    user_img = cv2.imread(filename)\n",
        "\n",
        "    if user_img is not None:\n",
        "        print(f\"\\n‚úÖ Bild '{filename}' geladen!\")\n",
        "        print(f\"   Gr√∂√üe: {user_img.shape[1]} √ó {user_img.shape[0]} Pixel\\n\")\n",
        "\n",
        "        # Alle Methoden anwenden\n",
        "        print(\"üîß Wende alle Verbesserungsmethoden an...\\n\")\n",
        "        compare_all_methods(user_img)\n",
        "\n",
        "        print(\"\\nüíæ M√∂chten Sie ein verbessertes Bild speichern?\")\n",
        "        print(\"   F√ºhren Sie die n√§chste Zelle aus!\")\n",
        "    else:\n",
        "        print(\"‚ùå Fehler beim Laden des Bildes\")\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è Kein Bild hochgeladen\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C0lZ868UwJgI"
      },
      "source": [
        "## Verbessertes Bild speichern"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gYEugOHAwJgI"
      },
      "outputs": [],
      "source": [
        "# W√§hlen Sie die gew√ºnschte Methode\n",
        "if 'user_img' in globals() and user_img is not None:\n",
        "    gray_user = cv2.cvtColor(user_img, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # CLAHE anwenden (meist beste Wahl)\n",
        "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
        "    improved = clahe.apply(gray_user)\n",
        "\n",
        "    # Speichern\n",
        "    output_filename = 'improved_image.png'\n",
        "    cv2.imwrite(output_filename, improved)\n",
        "\n",
        "    print(f\"‚úÖ Verbessertes Bild gespeichert als '{output_filename}'\")\n",
        "\n",
        "    # Download\n",
        "    files.download(output_filename)\n",
        "    print(\"üì• Download gestartet!\")\n",
        "\n",
        "    # Anzeigen\n",
        "    fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
        "    axes[0].imshow(gray_user, cmap='gray')\n",
        "    axes[0].set_title('Vorher', fontsize=14, fontweight='bold')\n",
        "    axes[0].axis('off')\n",
        "\n",
        "    axes[1].imshow(improved, cmap='gray')\n",
        "    axes[1].set_title('Nachher (CLAHE)', fontsize=14, fontweight='bold')\n",
        "    axes[1].axis('off')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è Bitte laden Sie zuerst ein Bild in der vorherigen Zelle hoch!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P1S2f8c7wJgR"
      },
      "source": [
        "---\n",
        "\n",
        "# üìö Teil 7: Zusammenfassung & Entscheidungshilfe\n",
        "\n",
        "## Welche Methode wann verwenden?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3KqrI__swJgR"
      },
      "outputs": [],
      "source": [
        "decision_tree = \"\"\"\n",
        "<style>\n",
        "table {\n",
        "    width: 100%;\n",
        "    border-collapse: collapse;\n",
        "    margin: 20px 0;\n",
        "}\n",
        "th, td {\n",
        "    border: 1px solid #ddd;\n",
        "    padding: 12px;\n",
        "    text-align: left;\n",
        "}\n",
        "th {\n",
        "    background-color: #2196F3;\n",
        "    color: white;\n",
        "}\n",
        "tr:nth-child(even) {\n",
        "    background-color: #f2f2f2;\n",
        "}\n",
        ".use-case { font-weight: bold; color: #1976D2; }\n",
        ".method { font-weight: bold; color: #388E3C; }\n",
        "</style>\n",
        "\n",
        "<h2>üéØ Entscheidungsbaum: Welche Methode?</h2>\n",
        "\n",
        "<table>\n",
        "  <tr>\n",
        "    <th>Problem</th>\n",
        "    <th>Empfohlene Methode</th>\n",
        "    <th>Warum?</th>\n",
        "  </tr>\n",
        "  <tr>\n",
        "    <td class=\"use-case\">üì∏ Unterbelichtetes Foto</td>\n",
        "    <td class=\"method\">CLAHE oder Standard Equalization</td>\n",
        "    <td>Bringt Details in Schatten zum Vorschein</td>\n",
        "  </tr>\n",
        "  <tr>\n",
        "    <td class=\"use-case\">‚òÄÔ∏è √úberbelichtetes Foto</td>\n",
        "    <td class=\"method\">CLAHE</td>\n",
        "    <td>Reduziert √úberbelichtung, erh√§lt Details</td>\n",
        "  </tr>\n",
        "  <tr>\n",
        "    <td class=\"use-case\">üå´Ô∏è Neblig/Kontrastarmes Bild</td>\n",
        "    <td class=\"method\">Standard Equalization oder CLAHE</td>\n",
        "    <td>Maximiert Kontrast, entfernt \"Nebel\"</td>\n",
        "  </tr>\n",
        "  <tr>\n",
        "    <td class=\"use-case\">üè• Medizinisches Bild (R√∂ntgen, MRT)</td>\n",
        "    <td class=\"method\">CLAHE</td>\n",
        "    <td>Beste lokale Kontrastverbesserung ohne √úberverst√§rkung</td>\n",
        "  </tr>\n",
        "  <tr>\n",
        "    <td class=\"use-case\">üõ∞Ô∏è Satellitenbild</td>\n",
        "    <td class=\"method\">CLAHE oder Histogram Matching</td>\n",
        "    <td>Lokale Details wichtig, Matching f√ºr Zeitreihen</td>\n",
        "  </tr>\n",
        "  <tr>\n",
        "    <td class=\"use-case\">üì± Smartphone-Automatik</td>\n",
        "    <td class=\"method\">CLAHE (Echtzeit-optimiert)</td>\n",
        "    <td>Gute Balance, nat√ºrliches Ergebnis</td>\n",
        "  </tr>\n",
        "  <tr>\n",
        "    <td class=\"use-case\">üé® K√ºnstlerischer Effekt</td>\n",
        "    <td class=\"method\">Standard Equalization</td>\n",
        "    <td>Dramatischer Kontrast, expressiv</td>\n",
        "  </tr>\n",
        "  <tr>\n",
        "    <td class=\"use-case\">üìä Dokument-Scan</td>\n",
        "    <td class=\"method\">Contrast Stretching oder Standard Equalization</td>\n",
        "    <td>Text muss lesbar sein, simpel reicht oft</td>\n",
        "  </tr>\n",
        "  <tr>\n",
        "    <td class=\"use-case\">üé¨ Video-Normalisierung</td>\n",
        "    <td class=\"method\">Histogram Matching</td>\n",
        "    <td>Konsistenz √ºber Frames hinweg</td>\n",
        "  </tr>\n",
        "  <tr>\n",
        "    <td class=\"use-case\">üî¨ Mikroskopie</td>\n",
        "    <td class=\"method\">CLAHE</td>\n",
        "    <td>Feine Details sichtbar machen ohne Artefakte</td>\n",
        "  </tr>\n",
        "</table>\n",
        "\n",
        "<h3>‚ö° Quick Decision:</h3>\n",
        "<ul>\n",
        "  <li><strong>Schnell & einfach?</strong> ‚Üí Contrast Stretching</li>\n",
        "  <li><strong>Maximum Kontrast?</strong> ‚Üí Standard Histogram Equalization</li>\n",
        "  <li><strong>Beste Qualit√§t?</strong> ‚Üí CLAHE (meist!)</li>\n",
        "  <li><strong>Farbanpassung?</strong> ‚Üí Histogram Matching</li>\n",
        "</ul>\n",
        "\n",
        "<h3>üéì Faustregel:</h3>\n",
        "<p><strong>Wenn unsicher ‚Üí Probiere CLAHE mit clipLimit=2.0, tileGridSize=(8,8)</strong></p>\n",
        "<p>Das ist in 80% der F√§lle die beste Wahl!</p>\n",
        "\"\"\"\n",
        "\n",
        "display(HTML(decision_tree))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NJhZMfCywJgR"
      },
      "source": [
        "## Wichtigste Konzepte - Cheat Sheet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AQcaDQGzwJgR"
      },
      "outputs": [],
      "source": [
        "cheat_sheet = \"\"\"\n",
        "<style>\n",
        ".code-box {\n",
        "    background-color: #f5f5f5;\n",
        "    border-left: 4px solid #2196F3;\n",
        "    padding: 10px;\n",
        "    margin: 10px 0;\n",
        "    font-family: monospace;\n",
        "}\n",
        ".tip {\n",
        "    background-color: #fff3cd;\n",
        "    border-left: 4px solid #ffc107;\n",
        "    padding: 10px;\n",
        "    margin: 10px 0;\n",
        "}\n",
        "</style>\n",
        "\n",
        "<h2>üìù Code Cheat Sheet</h2>\n",
        "\n",
        "<h3>1. Histogramm berechnen und anzeigen:</h3>\n",
        "<div class=\"code-box\">\n",
        "# Histogramm berechnen<br>\n",
        "hist = cv2.calcHist([image], [0], None, [256], [0, 256])<br>\n",
        "<br>\n",
        "# Anzeigen<br>\n",
        "plt.plot(hist)<br>\n",
        "plt.xlim([0, 256])<br>\n",
        "plt.show()\n",
        "</div>\n",
        "\n",
        "<h3>2. Standard Histogram Equalization:</h3>\n",
        "<div class=\"code-box\">\n",
        "# Graustufenbild<br>\n",
        "equalized = cv2.equalizeHist(gray_image)<br>\n",
        "<br>\n",
        "# Farbbild (YCrCb-Methode)<br>\n",
        "ycrcb = cv2.cvtColor(image, cv2.COLOR_BGR2YCrCb)<br>\n",
        "ycrcb[:, :, 0] = cv2.equalizeHist(ycrcb[:, :, 0])<br>\n",
        "result = cv2.cvtColor(ycrcb, cv2.COLOR_YCrCb2BGR)\n",
        "</div>\n",
        "\n",
        "<h3>3. CLAHE:</h3>\n",
        "<div class=\"code-box\">\n",
        "# CLAHE-Objekt erstellen<br>\n",
        "clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))<br>\n",
        "<br>\n",
        "# Anwenden<br>\n",
        "result = clahe.apply(gray_image)\n",
        "</div>\n",
        "\n",
        "<div class=\"tip\">\n",
        "üí° <strong>Tipp:</strong> clipLimit kontrolliert die St√§rke:<br>\n",
        "&nbsp;&nbsp;&nbsp;‚Ä¢ 1.0-2.0: Sanft (nat√ºrlich)<br>\n",
        "&nbsp;&nbsp;&nbsp;‚Ä¢ 2.0-4.0: Standard (empfohlen)<br>\n",
        "&nbsp;&nbsp;&nbsp;‚Ä¢ >4.0: Stark (kann √ºbertrieben wirken)\n",
        "</div>\n",
        "\n",
        "<h3>4. Contrast Stretching:</h3>\n",
        "<div class=\"code-box\">\n",
        "min_val = image.min()<br>\n",
        "max_val = image.max()<br>\n",
        "stretched = ((image - min_val) / (max_val - min_val) * 255).astype(np.uint8)\n",
        "</div>\n",
        "\n",
        "<h3>5. RGB-Histogramme (alle Kan√§le):</h3>\n",
        "<div class=\"code-box\">\n",
        "colors = ('b', 'g', 'r')<br>\n",
        "for i, color in enumerate(colors):<br>\n",
        "&nbsp;&nbsp;&nbsp;&nbsp;hist = cv2.calcHist([image], [i], None, [256], [0, 256])<br>\n",
        "&nbsp;&nbsp;&nbsp;&nbsp;plt.plot(hist, color=color)\n",
        "</div>\n",
        "\"\"\"\n",
        "\n",
        "display(HTML(cheat_sheet))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mb4XZ9-2wJgR"
      },
      "source": [
        "---\n",
        "\n",
        "## üéØ Lernziel-Check\n",
        "\n",
        "Kannst du die folgenden Fragen beantworten?\n",
        "\n",
        "### Grundlagen:\n",
        "‚òëÔ∏è Was zeigt ein Histogramm und wie interpretiert man es?\n",
        "\n",
        "‚òëÔ∏è Woran erkennt man ein unter-/√ºberbelichtetes Bild im Histogramm?\n",
        "\n",
        "‚òëÔ∏è Was bedeutet \"voller Dynamikbereich\"?\n",
        "\n",
        "### Methoden:\n",
        "‚òëÔ∏è Wie funktioniert Histogram Equalization im Prinzip?\n",
        "\n",
        "‚òëÔ∏è Was ist der Unterschied zwischen Standard-Equalization und CLAHE?\n",
        "\n",
        "‚òëÔ∏è Wann verwendet man Contrast Stretching vs. Equalization?\n",
        "\n",
        "‚òëÔ∏è Warum verwendet man bei Farbbildern den YCrCb-Farbraum?\n",
        "\n",
        "### Anwendung:\n",
        "‚òëÔ∏è Welche Methode f√ºr unterbelichtete Fotos?\n",
        "\n",
        "‚òëÔ∏è Welche Parameter beeinflussen CLAHE und wie?\n",
        "\n",
        "‚òëÔ∏è Wann w√ºrde man Histogram Matching verwenden?\n",
        "\n",
        "---\n",
        "\n",
        "## üìö Weiterf√ºhrende Themen\n",
        "\n",
        "- **Lokale Histogramm-Equalization** (sliding window)\n",
        "- **Multi-Histogramm-Equalization** (f√ºr Farbbilder)\n",
        "- **Histogramm-basierte Segmentierung** (Otsu's Method)\n",
        "- **Tone Mapping** (HDR ‚Üí LDR)\n",
        "- **Gamma-Korrektur** (nicht-lineare Transformation)\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.0"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}